{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encrypted BSAVNN: Lung Cancer Detection using Basis Scaling and Activations Vectorized Neural Networks (Direct Execution - Cleaned)\n",
    "\n",
    "This Jupyter Notebook integrates your original BSAVNN implementation logic and extends it to include performance evaluation and graph generation for a lung cancer detection task. **The `if __name__ == \"__main__\":` guard has been removed** to ensure direct execution of the main logic within the notebook environment, helping troubleshoot cases where output might not appear. **All unnecessary semicolons have also been removed.**\n",
    "\n",
    "**Note:** For this notebook to run as intended, you should have:\n",
    "- A pre-trained PyTorch model saved as `lung_cancer_model.pth`.\n",
    "- Test data in `test.csv` and corresponding labels in `y_test.csv`.\n",
    "- Required Python libraries (`pandas`, `torch`, `numpy`, `matplotlib`, `scikit-learn`, `psutil`).\n",
    "\n",
    "If `lung_cancer_model.pth`, `test.csv`, or `y_test.csv` are not found, the notebook will generate dummy data and a dummy model structure. Accuracy metrics will not be meaningful in this case, but performance overhead analysis will still be valid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import streamlit as st # Not directly used in the core logic, but kept as per your original script\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler # Not directly used in this script but kept as per original\n",
    "import sys\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "# --- Add this line here to ensure plots appear inline in Jupyter/VS Code ---\n",
    "%matplotlib inline \n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# --- Utility Functions for Performance Measurement ---\n",
    "class MemoryMonitor:\n",
    "    def __enter__(self):\n",
    "        self.process = psutil.Process(os.getpid())\n",
    "        self.initial_mem = self.process.memory_info().rss # in bytes\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.final_mem = self.process.memory_info().rss # in bytes\n",
    "\n",
    "# MODIFIED: do_normal now returns y_pred_normal for classification_report\n",
    "def do_normal(model, test_data, y_test_labels):\n",
    "    start_time = time.perf_counter()\n",
    "    y_pred_normal = []\n",
    "    with torch.no_grad():\n",
    "        for index, row in test_data.iterrows():\n",
    "            input_tensor = torch.tensor(row.values, dtype=torch.float32).unsqueeze(0)\n",
    "            output = model(input_tensor).squeeze(0) \n",
    "            predicted_class = int(output.item() > 0.5) # FIX: Convert boolean to int directly\n",
    "            y_pred_normal.append(predicted_class)\n",
    "    end_time = time.perf_counter()\n",
    "    total_time_ms = (end_time - start_time) * 1000\n",
    "    acc = accuracy_score(y_test_labels, y_pred_normal)\n",
    "    \n",
    "    # Return y_pred_normal so it can be used for classification_report outside\n",
    "    return acc, total_time_ms, y_pred_normal\n",
    "\n",
    "# --- YOUR ORIGINAL CODE STARTS HERE (modified ONLY for correctness and scope) ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeepNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 48),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(48, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Modified: `input_dim_for_model` is now an explicit argument\n",
    "def load_model(input_dim_for_model):\n",
    "    saved_model = DeepNN(input_dim_for_model)\n",
    "    try:\n",
    "        # Check if the loaded model's input features match the current input_dim\n",
    "        # FIX: Load checkpoint first to inspect its shape before loading state_dict\n",
    "        checkpoint = torch.load(\"lung_cancer_model.pth\")\n",
    "        if 'model.0.weight' in checkpoint and checkpoint['model.0.weight'].shape[1] == input_dim_for_model:\n",
    "            saved_model.load_state_dict(checkpoint)\n",
    "            print(f\"Model for input_dim={input_dim_for_model} loaded successfully from lung_cancer_model.pth.\")\n",
    "        else:\n",
    "            print(f\"Warning: Pre-trained model in .pth has input_dim {checkpoint['model.0.weight'].shape[1] if 'model.0.weight' in checkpoint else 'N/A'}, but current is {input_dim_for_model}. Initializing with random weights.\")\n",
    "            for param in saved_model.parameters():\n",
    "                if param.dim() > 1:\n",
    "                    nn.init.kaiming_uniform_(param, nonlinearity='relu')\n",
    "                else:\n",
    "                    nn.init.constant_(param, 0.0)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"lung_cancer_model.pth not found for input_dim={input_dim_for_model}. Initializing with random weights.\")\n",
    "        for param in saved_model.parameters():\n",
    "            if param.dim() > 1:\n",
    "                nn.init.kaiming_uniform_(param, nonlinearity='relu')\n",
    "            else:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "    except Exception as e: \n",
    "        print(f\"An unexpected error occurred loading model: {e}. Initializing with random weights for input_dim={input_dim_for_model}.\")\n",
    "        for param in saved_model.parameters():\n",
    "            if param.dim() > 1:\n",
    "                nn.init.kaiming_uniform_(param, nonlinearity='relu')\n",
    "            else:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "    \n",
    "    saved_model.eval() \n",
    "    return saved_model.model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prints for saved_model_wb and its layer shapes were part of your original global execution.\n",
    "# They will now run within the main execution flow after `saved_model_wb` is loaded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BSAVNN Core Logic\n",
    "The functions below implement the basis scaling, activation vectorization, and secure ReLU logic. Their signatures have been minimally adjusted to pass necessary variables (like `an_plus_1_val` and `eval_vec`) explicitly, ensuring correct scope and execution within the comprehensive testing framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dynamic_keys(input_dim_val):\n",
    "    \"\"\"Initializes encryption, decryption, and evaluation keys dynamically based on input_dim.\"\"\"\n",
    "    enc_vec_dyn = torch.tensor(np.random.uniform(0.9, 1.1, input_dim_val), dtype=torch.float32)\n",
    "    an_plus_1_dyn = torch.tensor(np.random.uniform(1.0, 2.0), dtype=torch.float32)\n",
    "    dec_vec_no_bias_dyn = 1 / enc_vec_dyn\n",
    "    dec_vec_dyn = torch.cat((dec_vec_no_bias_dyn, torch.tensor([1 / an_plus_1_dyn.item()], dtype=torch.float32)))\n",
    "    k_dyn = 1.0 \n",
    "    eval_vec_dyn = dec_vec_dyn / k_dyn\n",
    "    eval_vec_dyn = eval_vec_dyn.view(-1, 1) \n",
    "    return enc_vec_dyn, an_plus_1_dyn, dec_vec_dyn, eval_vec_dyn, k_dyn\n",
    "\n",
    "def encrypt_data(input_values, enc_vec_arg):\n",
    "    \"\"\"Encrypts input values using the provided encryption vector.\"\"\"\n",
    "    input_tensor = torch.tensor(input_values, dtype=torch.float32) \n",
    "    enc_inp = enc_vec_arg * input_tensor \n",
    "    return enc_inp\n",
    "\n",
    "def decrypt_ans(activation_matrix_final_layer, dec_vec_arg, k_val):\n",
    "    \"\"\"Decrypts the final activations to obtain probabilities.\"\"\"\n",
    "    dec_vec_reshaped = dec_vec_arg.view(-1, 1).to(torch.float32) \n",
    "    decrypted_output_scalar = torch.matmul(activation_matrix_final_layer.unsqueeze(0), dec_vec_reshaped).item()\n",
    "    true_logit = k_val * decrypted_output_scalar\n",
    "    final_ans = torch.sigmoid(torch.tensor(true_logit, dtype=torch.float32))\n",
    "    return final_ans\n",
    "\n",
    "def input_layer_calc(initial_activation_matrix_list_dummy, saved_model_wb_arg, enc_inp, eval_vec_arg, an_plus_1_val):\n",
    "    \"\"\"Calculates the first layer's activations with BSAVNN logic.\"\"\"\n",
    "    input_layer_weights = saved_model_wb_arg[0].weight.data.T.to(torch.float32) \n",
    "    input_layer_bias = saved_model_wb_arg[0].bias.data.to(torch.float32) \n",
    "\n",
    "    activation_matrix_current_layer = [] \n",
    "\n",
    "    for col_idx in range(input_layer_weights.shape[1]):\n",
    "        col_vector = input_layer_weights[:, col_idx]\n",
    "        elementwise_product = enc_inp * col_vector\n",
    "        \n",
    "        scaled_bias_term = (an_plus_1_val * input_layer_bias[col_idx]).unsqueeze(0)\n",
    "        elementwise_product = torch.cat((elementwise_product, scaled_bias_term))\n",
    "        \n",
    "        activation_matrix_current_layer.append(elementwise_product)\n",
    "\n",
    "    activation_matrix_current_layer_tensor = torch.stack(activation_matrix_current_layer)\n",
    "\n",
    "    relu_output = []\n",
    "    for row_vector in activation_matrix_current_layer_tensor:\n",
    "        row_sum = torch.matmul(row_vector.unsqueeze(0), eval_vec_arg).item() \n",
    "        relu_value = F.relu(torch.tensor(row_sum, dtype=torch.float32))\n",
    "        relu_output.append(relu_value)\n",
    "\n",
    "    relu_output_tensor = torch.tensor(relu_output, dtype=torch.float32)\n",
    "    final_activation_matrix = torch.stack([row_vector if relu_value > 0 else torch.zeros_like(row_vector) \n",
    "                                          for row_vector, relu_value in zip(activation_matrix_current_layer_tensor, relu_output_tensor)])\n",
    "    return final_activation_matrix\n",
    "\n",
    "def intermediate_layer_calc(activation_matrix, saved_model_wb_arg, eval_vec_arg, an_plus_1_val, layer_index):\n",
    "    \"\"\"Calculates intermediate layer activations with BSAVNN logic.\"\"\"\n",
    "    intermediate_weights = saved_model_wb_arg[layer_index].weight.data.T.to(torch.float32) \n",
    "    intermediate_biases = saved_model_wb_arg[layer_index].bias.data.to(torch.float32) \n",
    "    \n",
    "    activation_matrix_new = []\n",
    "\n",
    "    for col_idx in range(intermediate_weights.shape[1]):\n",
    "        col_vector = intermediate_weights[:, col_idx]\n",
    "        scaled_activation = activation_matrix * col_vector.view(-1,1)\n",
    "        row_vector = scaled_activation.sum(dim=0)\n",
    "        \n",
    "        row_vector[-1] += (an_plus_1_val * intermediate_biases[col_idx]).item() \n",
    "        \n",
    "        activation_matrix_new.append(row_vector)\n",
    "\n",
    "    activation_matrix_new_tensor = torch.stack(activation_matrix_new)\n",
    "\n",
    "    is_final_linear_layer = (layer_index == 10)\n",
    "\n",
    "    if not is_final_linear_layer:\n",
    "        relu_output = []\n",
    "        for row_vector in activation_matrix_new_tensor:\n",
    "            row_sum = torch.matmul(row_vector.unsqueeze(0), eval_vec_arg).item()\n",
    "            relu_value = F.relu(torch.tensor(row_sum, dtype=torch.float32))\n",
    "            relu_output.append(relu_value)\n",
    "\n",
    "        relu_output_tensor = torch.tensor(relu_output, dtype=torch.float32)\n",
    "        activation_matrix_out = torch.stack([row_vector if relu_value > 0 else torch.zeros_like(row_vector) \n",
    "                                             for row_vector, relu_value in zip(activation_matrix_new_tensor, relu_output_tensor)])\n",
    "    else:\n",
    "        activation_matrix_out = activation_matrix_new_tensor \n",
    "        \n",
    "    return activation_matrix_out\n",
    "\n",
    "def bsavnn_model_pred(input_values, saved_model_wb_arg, enc_vec_arg, eval_vec_arg, an_plus_1_val):\n",
    "    \"\"\"Performs a full BSAVNN forward pass for one sample.\"\"\"\n",
    "    enc_inp = encrypt_data(input_values, enc_vec_arg) \n",
    "\n",
    "    current_activation_matrix = input_layer_calc([], saved_model_wb_arg, enc_inp, eval_vec_arg, an_plus_1_val)\n",
    "\n",
    "    for layer_idx in range(2, 11, 2): \n",
    "        current_activation_matrix = intermediate_layer_calc(current_activation_matrix, saved_model_wb_arg, eval_vec_arg, an_plus_1_val, layer_idx)\n",
    "    \n",
    "    return current_activation_matrix \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution Block and Performance Evaluation\n",
    "This section orchestrates the loading of data and models, runs the BSAVNN and plaintext inference, and generates the required performance graphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for running evaluation for varying input dimensions\n",
    "def run_evaluation_for_input_dim(current_input_dim, num_samples=100):\n",
    "    dummy_test_data = pd.DataFrame(np.random.rand(num_samples, current_input_dim))\n",
    "    dummy_y_test = [np.random.randint(0, 2) for _ in range(num_samples)] \n",
    "\n",
    "    # Initialize keys and model for THIS specific input_dim\n",
    "    enc_vec_local, an_plus_1_local, dec_vec_local, eval_vec_local, k_local = initialize_dynamic_keys(current_input_dim)\n",
    "    saved_model_wb_local = load_model(current_input_dim) \n",
    "\n",
    "    # Plaintext Model Evaluation\n",
    "    _, normal_inference_time_ms, _ = do_normal(DeepNN(current_input_dim), dummy_test_data, dummy_y_test) # Discard y_pred_normal as it's not used here\n",
    "    \n",
    "    # BSAVNN Model Evaluation\n",
    "    total_bsavnn_time_ms = 0\n",
    "    total_encrypt_time_ms = 0\n",
    "    total_decrypt_time_ms = 0\n",
    "    total_bsavnn_server_inference_time_ms = 0 \n",
    "\n",
    "    # For memory, we compute theoretical activation memory (as discussed in your paper)\n",
    "    # Max neurons in hidden layers: 64 (from input_dim to 64)\n",
    "    bsavnn_max_activations_elements = 64 * (current_input_dim + 1) \n",
    "    bsavnn_activation_mem_bytes = bsavnn_max_activations_elements * 4 \n",
    "    \n",
    "    # Plaintext NN: Max intermediate layer size (e.g., 64 neurons * 1 element)\n",
    "    plaintext_max_activations_elements = 64 \n",
    "    plaintext_activation_mem_bytes = plaintext_max_activations_elements * 4\n",
    "\n",
    "    for idx in range(num_samples):\n",
    "        input_row = dummy_test_data.iloc[idx].values\n",
    "\n",
    "        start_encrypt = time.perf_counter()\n",
    "        encrypted_input = encrypt_data(input_row, enc_vec_local) \n",
    "        end_encrypt = time.perf_counter()\n",
    "        total_encrypt_time_ms += (end_encrypt - start_encrypt) * 1000\n",
    "\n",
    "        start_inference = time.perf_counter()\n",
    "        final_encrypted_logit_vector = bsavnn_model_pred(input_row, saved_model_wb_local, enc_vec_local, eval_vec_local, an_plus_1_local)\n",
    "        end_inference = time.perf_counter()\n",
    "        total_bsavnn_server_inference_time_ms += (end_inference - start_inference) * 1000\n",
    "\n",
    "        start_decrypt = time.perf_counter()\n",
    "        # FIX: Access the single output vector correctly for decryption\n",
    "        _ = decrypt_ans(final_encrypted_logit_vector[0], dec_vec_local, k_local) \n",
    "        end_decrypt = time.perf_counter()\n",
    "        total_decrypt_time_ms += (end_decrypt - start_decrypt) * 1000\n",
    "\n",
    "    return {\n",
    "        'input_dim': current_input_dim,\n",
    "        'normal_inference_time_ms': normal_inference_time_ms / num_samples,\n",
    "        'bsavnn_total_inference_time_ms': (total_bsavnn_encrypt_time + total_bsavnn_server_inference_time_ms + total_bsavnn_decrypt_time) / num_samples,\n",
    "        'bsavnn_encrypt_time_ms': total_encrypt_time_ms / num_samples,\n",
    "        'bsavnn_decrypt_time_ms': total_decrypt_time_ms / num_samples,\n",
    "        'bsavnn_server_inference_time_ms': total_bsavnn_server_inference_time_ms / num_samples,\n",
    "        'bsavnn_activation_mem_mb': bsavnn_activation_mem_bytes / (1024**2),\n",
    "        'plaintext_activation_mem_mb': plaintext_activation_mem_bytes / (1024**2),\n",
    "    }\n",
    "\n",
    "# Helper to plot graphs (Defined here, outside the main execution block)\n",
    "def plot_performance_graphs(results_df_plot):\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    fig_width = 10\n",
    "    fig_height = 6\n",
    "\n",
    "    os.makedirs('figures', exist_ok=True)\n",
    "\n",
    "    # Time vs. Input Size\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    plt.plot(results_df_plot['input_dim'], results_df_plot['normal_inference_time_ms'], label='Plaintext NN', marker='o', color='blue')\n",
    "    plt.plot(results_df_plot['input_dim'], results_df_plot['bsavnn_total_inference_time_ms'], label='BSAVNN (Total End-to-End)', marker='x', color='red')\n",
    "    plt.plot(results_df_plot['input_dim'], results_df_plot['bsavnn_server_inference_time_ms'], label='BSAVNN (Server Only)', marker='s', color='green', linestyle='--')\n",
    "    plt.xlabel('Input Dimension ($n$)')\n",
    "    plt.ylabel('Inference Time (ms)')\n",
    "    plt.title('Computation Time vs. Input Dimension')\n",
    "    plt.legend()\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./figures/time_vs_input_size.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Memory Usage vs. Input Size\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    plt.plot(results_df_plot['input_dim'], results_df_plot['plaintext_activation_mem_mb'], label='Plaintext NN (Activations)', marker='o', color='blue')\n",
    "    plt.plot(results_df_plot['input_dim'], results_df_plot['bsavnn_activation_mem_mb'], label='BSAVNN (Activations)', marker='x', color='red')\n",
    "    plt.xlabel('Input Dimension ($n$)')\n",
    "    plt.ylabel('Memory Usage (MB)')\n",
    "    plt.title('Activation Memory Usage vs. Input Dimension')\n",
    "    plt.legend()\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./figures/memory_vs_input_size.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Relative Overhead vs. Input Size\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    overhead_percentage = ((results_df_plot['bsavnn_total_inference_time_ms'] - results_df_plot['normal_inference_time_ms']) / results_df_plot['normal_inference_time_ms']) * 100\n",
    "    plt.plot(results_df_plot['input_dim'], overhead_percentage, label='BSAVNN Relative Time Overhead', marker='o', color='purple')\n",
    "    plt.xlabel('Input Dimension ($n$)')\n",
    "    plt.ylabel('Relative Overhead (%)')\n",
    "    plt.title('BSAVNN Relative Time Overhead vs. Input Dimension')\n",
    "    plt.legend()\n",
    "    plt.xscale('log')\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./figures/relative_overhead_vs_input_size.png')\n",
    "    plt.show()\n",
    "\n",
    "# --- Main Execution Logic (now directly executed without if __name__ guard) ---\n",
    "\n",
    "# --- Configuration ---\n",
    "actual_input_dim = 15 # Default for `test.csv` if not found/overridden\n",
    "paper_input_dim = 16384 # As specified in your paper for the 128x128 image (e.g., for plotting)\n",
    "num_samples_for_graphs = 50 # Number of samples to use for each input_dim when generating graphs\n",
    "\n",
    "# --- Data Loading and Initialization ---\n",
    "test_data = pd.DataFrame()\n",
    "y_test = np.array([])\n",
    "try:\n",
    "    test_data_path = \"test.csv\"\n",
    "    y_test_path = \"y_test.csv\"\n",
    "    test_data = pd.read_csv(test_data_path)\n",
    "    y_test = pd.read_csv(y_test_path).values.flatten()\n",
    "    actual_input_dim = test_data.shape[1] \n",
    "    print(f\"Loaded test data with {actual_input_dim} features.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Test data CSVs not found. Generating dummy data for accuracy test.\")\n",
    "    actual_input_dim = 15 \n",
    "    test_data = pd.DataFrame(np.random.rand(100, actual_input_dim))\n",
    "    y_test = np.random.randint(0, 2, 100)\n",
    "\n",
    "# Initialize global keys for the main execution block (accuracy test)\n",
    "global enc_vec, an_plus_1, dec_vec, k, eval_vec \n",
    "enc_vec, an_plus_1, dec_vec, eval_vec, k = initialize_dynamic_keys(actual_input_dim)\n",
    "\n",
    "# Load the plaintext model's sequential layers to global variable\n",
    "global saved_model_wb \n",
    "saved_model_wb = load_model(actual_input_dim)\n",
    "\n",
    "# --- BSAVNN Single Inference Demonstration ---\n",
    "print(\"\\n--- BSAVNN Single Inference Demonstration ---\")\n",
    "if not test_data.empty:\n",
    "    sample_input_values = test_data.iloc[0].values\n",
    "    \n",
    "    start_encryption_time = time.perf_counter()\n",
    "    encrypted_sample_input = encrypt_data(sample_input_values, enc_vec) \n",
    "    end_encryption_time = time.perf_counter()\n",
    "    \n",
    "    start_bsavnn_inference_time = time.perf_counter()\n",
    "    final_encrypted_logit_vector_sample = bsavnn_model_pred(sample_input_values, saved_model_wb, enc_vec, eval_vec, an_plus_1)\n",
    "    end_bsavnn_inference_time = time.perf_counter()\n",
    "    \n",
    "    start_decryption_time = time.perf_counter()\n",
    "    final_predicted_prob_sample = decrypt_ans(final_encrypted_logit_vector_sample[0], dec_vec, k) \n",
    "    end_decryption_time = time.perf_counter()\n",
    "\n",
    "    print(f\"Sample Input (first 5 features): {sample_input_values[:5]}\")\n",
    "    print(f\"Encrypted Input (first 5 features): {encrypted_sample_input[:5].tolist()}\")\n",
    "    print(f\"Final Encrypted Logit Vector (truncated): {final_encrypted_logit_vector_sample[0, :min(5, final_encrypted_logit_vector_sample.shape[1])].tolist()}\")\n",
    "    print(f\"Decrypted Final Probability for sample: {final_predicted_prob_sample.item():.4f}\")\n",
    "    print(f\"Encryption Time: {(end_encryption_time - start_encryption_time) * 1000:.3f} ms\")\n",
    "    print(f\"Server Inference Time: {(end_bsavnn_inference_time - start_bsavnn_inference_time) * 1000:.3f} ms\")\n",
    "    print(f\"Decryption Time: {(end_decryption_time - start_decryption_time) * 1000:.3f} ms\")\n",
    "else:\n",
    "    print(\"No test data loaded for single inference demonstration.\")\n",
    "\n",
    "# --- Run full BSAVNN inference for accuracy and full timing ---\n",
    "print(\"\\n--- Running Full BSAVNN Inference for Metrics ---\")\n",
    "y_pred_bsavnn = []\n",
    "total_bsavnn_encrypt_time = 0\n",
    "total_bsavnn_server_time = 0\n",
    "total_bsavnn_decrypt_time = 0\n",
    "\n",
    "for index, row in test_data.iterrows():\n",
    "    start_time = time.perf_counter()\n",
    "    encrypted_input_row = encrypt_data(row.values, enc_vec)\n",
    "    end_time = time.perf_counter()\n",
    "    total_bsavnn_encrypt_time += (end_time - start_time) * 1000\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    final_encrypted_logit_vector_row = bsavnn_model_pred(row.values, saved_model_wb, enc_vec, eval_vec, an_plus_1)\n",
    "    end_time = time.perf_counter()\n",
    "    total_bsavnn_server_time += (end_time - start_time) * 1000\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    final_prob_row = decrypt_ans(final_encrypted_logit_vector_row[0], dec_vec, k)\n",
    "    end_time = time.perf_counter()\n",
    "    total_bsavnn_decrypt_time += (end_time - start_time) * 1000\n",
    "\n",
    "    predicted_class = int(final_prob_row.item() > 0.5)\n",
    "    y_pred_bsavnn.append(predicted_class)\n",
    "\n",
    "bsavnn_acc = accuracy_score(y_test, y_pred_bsavnn)\n",
    "print(\"\\nâœ… BSAVNN Test Accuracy:\", round(bsavnn_acc * 100, 2), \"%\")\n",
    "print(\"\\nðŸ“Š BSAVNN Classification Report:\\n\", classification_report(y_test, y_pred_bsavnn, zero_division=0))\n",
    "print(f\"BSAVNN Average Encryption Time: {total_bsavnn_encrypt_time / len(test_data):.3f} ms/sample\")\n",
    "print(f\"BSAVNN Average Server Inference Time: {total_bsavnn_server_time / len(test_data):.3f} ms/sample\")\n",
    "print(f\"BSAVNN Average Decryption Time: {total_bsavnn_decrypt_time / len(test_data):.3f} ms/sample\")\n",
    "print(f\"BSAVNN Average Total End-to-End Time: {(total_bsavnn_encrypt_time + total_bsavnn_server_time + total_bsavnn_decrypt_time) / len(test_data):.3f} ms/sample\")\n",
    "\n",
    "# --- Run Plaintext inference for comparison ---\n",
    "print(\"\\n--- Running Plaintext Inference for Comparison ---\")\n",
    "original_plaintext_model = DeepNN(actual_input_dim)\n",
    "try:\n",
    "    original_plaintext_model.load_state_dict(torch.load(\"lung_cancer_model.pth\"))\n",
    "    original_plaintext_model.eval()\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: lung_cancer_model.pth not found for plaintext model. Using random weights.\")\n",
    "    for param in original_plaintext_model.parameters():\n",
    "        if param.dim() > 1:\n",
    "            nn.init.kaiming_uniform_(param, nonlinearity='relu')\n",
    "        else:\n",
    "            nn.init.constant_(param, 0.0)\n",
    "    \n",
    "normal_acc, normal_time_ms_total, y_pred_normal = do_normal(original_plaintext_model, test_data, y_test) \n",
    "print(\"Normal Model Accuracy:\", round(normal_acc * 100, 2), \"%\")\n",
    "print(\"\\nðŸ“Š Normal Classification Report:\\n\", classification_report(y_test, y_pred_normal, zero_division=0)) \n",
    "print(f\"Normal Model Average Inference Time: {normal_time_ms_total / len(test_data):.3f} ms/sample\")\n",
    "\n",
    "\n",
    "# --- Generate Data for Graphs (varying input dimensions) ---\n",
    "print(\"\\n--- Generating Data for Performance Graphs (this may take a while for large dims) ---\")\n",
    "input_dims_to_test = [4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192]\n",
    "if paper_input_dim not in input_dims_to_test and paper_input_dim > max(input_dims_to_test):\n",
    "    input_dims_to_test.append(paper_input_dim)\n",
    "input_dims_to_test.sort()\n",
    "\n",
    "performance_results = []\n",
    "for dim in input_dims_to_test:\n",
    "    print(f\"Evaluating for input_dim={dim} with {num_samples_for_graphs} samples...\")\n",
    "    result = run_evaluation_for_input_dim(dim, num_samples=num_samples_for_graphs)\n",
    "    performance_results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(performance_results)\n",
    "print(\"\\nPerformance Results Data:\")\n",
    "print(results_df.to_string()) \n",
    "\n",
    "# --- Plot Graphs ---\n",
    "print(\"\\n--- Plotting Performance Graphs ---\")\n",
    "\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "\n",
    "def plot_performance_graphs(results_df_plot):\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    fig_width = 10\n",
    "    fig_height = 6\n",
    "\n",
    "    # Time vs. Input Size\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    plt.plot(results_df_plot['input_dim'], results_df_plot['normal_inference_time_ms'], label='Plaintext NN', marker='o', color='blue')\n",
    "    plt.plot(results_df_plot['input_dim'], results_df_plot['bsavnn_total_inference_time_ms'], label='BSAVNN (Total End-to-End)', marker='x', color='red')\n",
    "    plt.plot(results_df_plot['input_dim'], results_df_plot['bsavnn_server_inference_time_ms'], label='BSAVNN (Server Only)', marker='s', color='green', linestyle='--')\n",
    "    plt.xlabel('Input Dimension ($n$)')\n",
    "    plt.ylabel('Inference Time (ms)')\n",
    "    plt.title('Computation Time vs. Input Dimension')\n",
    "    plt.legend()\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./figures/time_vs_input_size.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Memory Usage vs. Input Size\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    plt.plot(results_df_plot['input_dim'], results_df_plot['plaintext_activation_mem_mb'], label='Plaintext NN (Activations)', marker='o', color='blue')\n",
    "    plt.plot(results_df_plot['input_dim'], results_df_plot['bsavnn_activation_mem_mb'], label='BSAVNN (Activations)', marker='x', color='red')\n",
    "    plt.xlabel('Input Dimension ($n$)')\n",
    "    plt.ylabel('Memory Usage (MB)')\n",
    "    plt.title('Activation Memory Usage vs. Input Dimension')\n",
    "    plt.legend()\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./figures/memory_vs_input_size.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Relative Overhead vs. Input Size\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    overhead_percentage = ((results_df_plot['bsavnn_total_inference_time_ms'] - results_df_plot['normal_inference_time_ms']) / results_df_plot['normal_inference_time_ms']) * 100\n",
    "    plt.plot(results_df_plot['input_dim'], overhead_percentage, label='BSAVNN Relative Time Overhead', marker='o', color='purple')\n",
    "    plt.xlabel('Input Dimension ($n$)')\n",
    "    plt.ylabel('Relative Overhead (%)')\n",
    "    plt.title('BSAVNN Relative Time Overhead vs. Input Dimension')\n",
    "    plt.legend()\n",
    "    plt.xscale('log')\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./figures/relative_overhead_vs_input_size.png')\n",
    "    plt.show()\n",
    "\n",
    "plot_performance_graphs(results_df) # Call the plotting function with the results DataFrame\n",
    "print(\"Graphs saved as time_vs_input_size.png, memory_vs_input_size.png, relative_overhead_vs_input_size.png in the 'figures' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
